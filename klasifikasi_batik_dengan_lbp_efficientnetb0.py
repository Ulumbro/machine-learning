# -*- coding: utf-8 -*-
"""Klasifikasi_Batik_Dengan_LBP_EfficientNetB0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hz6vnenfpyESGToYNvKnZlrKlZ6gAGef

:<H2 style="font-family:verdana;"> <center>Batik Classification using Deep Convolutional Neural Networks, Transfer Learning & LBP</center> </H2>

***

<center><img src='https://media2.giphy.com/media/ZXI7HmWbNplmv0OTK6/200.gif' height=150px width=200px></center>


# ‚ùóDisclaimer:
<div style="background-color:#d4f1f4; padding: 20px;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em">Periksa setiap cell kode ketika menjalankan kodenya, jangan sampai ada yang skip agar tidak ada error, karena kode saling berkaitan^^</p>
</div>

# **Upload dataset terlebih dahulu**
Bisa pakai kode ini, atau drag n drop file dataset .zip langsung kedalam directory content
"""

from google.colab import files
uploaded = files.upload()

"""# **Ekstrak dataset .zip**
Gunakan kode dibawah ini untuk mengekstrak file .zip dataset yang sudah di upload agar datasetnya bisa digunakan untuk klasifikasi.

"""

import zipfile
local_zip = 'batik.zip'
extract_zip = zipfile.ZipFile(local_zip, 'r')
extract_zip.extractall('')
extract_zip.close()

"""# **Import modul dan library yang dibutuhkan**"""

!pip install keras_preprocessing

# Import Data Science Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split

# Tensorflow Libraries
from tensorflow import keras
from tensorflow.keras import layers,models
from keras_preprocessing.image import ImageDataGenerator
from keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import Model
from tensorflow.keras.layers.experimental import preprocessing

# System libraries
from pathlib import Path
import os.path
import random

# Visualization Libraries
import matplotlib.cm as cm
import cv2
import seaborn as sns

sns.set_style('darkgrid')

# Metrics
from sklearn.metrics import classification_report, confusion_matrix
import itertools

"""# **Membuat Fungsi Helper**
Kode ini digunakan untuk mengunduh sebuah file Python yang disebut `helper_functions.py` dari GitHub dan mengimpor serangkaian fungsi bantu dari file tersebut ke dalam notebook yang sedang digunakan. Fungsi-fungsi ini kemungkinan besar akan digunakan untuk membantu proses pelatihan, evaluasi, dan visualisasi model pembelajaran mesin dalam notebook tersebut.
"""

!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py

# Import series of helper functions for our notebook
from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot

"""# **Konfigurasi Batch dan Penjelajahan Dataset untuk Pelatihan Model Klasifikasi Batik**
Kode ini menetapkan ukuran batch (batch size) dan ukuran target (target size) untuk proses pelatihan model. Selanjutnya, kode menggunakan fungsi `walk_through_dir()` untuk menjelajahi setiap direktori dalam dataset yang diberikan. Dalam kasus ini, datasetnya adalah direktori yang berisi data pelatihan untuk klasifikasi batik, dan fungsi ini digunakan untuk menampilkan informasi tentang dataset, seperti jumlah sampel di setiap kelas dan nama kelasnya.
"""

BATCH_SIZE = 32
TARGET_SIZE = (224, 224)

# Walk through each directory
dataset = "/content/batik/train"
walk_through_dir(dataset);

"""# **Visualisasi Distribusi Label Teratas dalam Dataset Gambar**
Tujuannya adalah untuk memvisualisasikan distribusi label teratas dalam dataset gambar yang sedang digunakan. Dengan menggunakan plot bar, kita dapat melihat seberapa seimbang atau tidak seimbangnya distribusi label dalam dataset. Hal ini penting untuk pemahaman awal tentang data yang akan digunakan dalam proses pelatihan model klasifikasi batik, serta untuk mengidentifikasi kelas-kelas yang mungkin memerlukan lebih banyak data atau perhatian khusus dalam proses pembuatan model.
"""

image_dir = Path(dataset)

# Get filepaths and labels
filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.png'))

labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

# Concatenate filepaths and labels
image_df = pd.concat([filepaths, labels], axis=1)

# Get the top 20 labels
label_counts = image_df['Label'].value_counts()[:20]

plt.figure(figsize=(20, 6))
sns.barplot(x=label_counts.index, y=label_counts.values, alpha=0.8, palette='dark:salmon_r')
plt.title('Distribution of Top 20 Labels in Image Dataset', fontsize=16)
plt.xlabel('Label', fontsize=14)
plt.ylabel('Count', fontsize=14)
plt.xticks(rotation=45)
plt.show()

"""# **Menampilkan Sampel Gambar dan Label dari Dataset**
Kode ini Menampilkan 16 gambar dari dataset berserta labelnya dalam bentuk grid 4x4. Tujuannya adalah untuk memberikan gambaran visual tentang variasi data yang ada dalam dataset, serta memastikan bahwa label-label yang terdapat pada dataset sesuai dengan konten visual gambar yang ditampilkan.
"""

# Display 16 picture of the dataset with their labels
random_index = np.random.randint(0, len(image_df), 16)
fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),
                        subplot_kw={'xticks': [], 'yticks': []})

for i, ax in enumerate(axes.flat):
    ax.imshow(plt.imread(image_df.Filepath[random_index[i]]))
    ax.set_title(image_df.Label[random_index[i]])
plt.tight_layout()
plt.show()

"""# **Error Level Analysis**
Fungsi-fungsi dalam kode dibawah ini digunakan untuk menghitung Error Level Analysis (ELA) dari gambar-gambar dalam dataset batik. ELA adalah teknik yang digunakan untuk mendeteksi area manipulasi pada gambar dengan membandingkan perbedaan kualitas kompresi antara gambar asli dan gambar yang telah dikompresi ulang. Tujuannya adalah untuk memvisualisasikan perbedaan kualitas kompresi pada gambar-gambar dalam dataset menggunakan skala ELA yang bervariasi.
"""

def compute_ela_cv(path, quality):
    temp_filename = 'temp_file_name.jpeg'
    SCALE = 15
    orig_img = cv2.imread(path)
    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)

    cv2.imwrite(temp_filename, orig_img, [cv2.IMWRITE_JPEG_QUALITY, quality])

    # read compressed image
    compressed_img = cv2.imread(temp_filename)

    # get absolute difference between img1 and img2 and multiply by scale
    diff = SCALE * cv2.absdiff(orig_img, compressed_img)
    return diff


def convert_to_ela_image(path, quality):
    temp_filename = 'temp_file_name.jpeg'
    ela_filename = 'temp_ela.png'
    image = Image.open(path).convert('RGB')
    image.save(temp_filename, 'JPEG', quality = quality)
    temp_image = Image.open(temp_filename)

    ela_image = ImageChops.difference(image, temp_image)

    extrema = ela_image.getextrema()
    max_diff = max([ex[1] for ex in extrema])
    if max_diff == 0:
        max_diff = 1

    scale = 255.0 / max_diff
    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)

    return ela_image


def random_sample(path, extension=None):
    if extension:
        items = Path(path).glob(f'*.{extension}')
    else:
        items = Path(path).glob(f'*')

    items = list(items)

    p = random.choice(items)
    return p.as_posix()

# View random sample from the dataset
p = random_sample('/content/batik/train/Batik Jepara')
orig = cv2.imread(p)
orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB) / 255.0
init_val = 100
columns = 3
rows = 3

fig=plt.figure(figsize=(15, 10))
for i in range(1, columns*rows +1):
    quality=init_val - (i-1) * 8
    img = compute_ela_cv(path=p, quality=quality)
    if i == 1:
        img = orig.copy()
    ax = fig.add_subplot(rows, columns, i)
    ax.title.set_text(f'q: {quality}')
    plt.imshow(img)
plt.show()

"""# **Data Praproses**
Kode ini digunakan untuk mempersiapkan data untuk pelatihan model klasifikasi batik. Langkah-langkah yang dilakukan meliputi:

1. Memisahkan data menjadi data pelatihan dan data uji.
2. Membuat generator gambar untuk data pelatihan dan data uji dengan menggunakan `ImageDataGenerator` dari TensorFlow.
3. Mendefinisikan fungsi untuk menerapkan transformasi Local Binary Pattern (LBP) pada gambar.
4. Memvisualisasikan 16 gambar acak dari dataset yang telah diubah dengan transformasi LBP.
5. Melakukan pemisahan data ke dalam tiga kategori: data pelatihan, data validasi, dan data uji dengan menggunakan `flow_from_dataframe()` dari generator gambar.
6. Menerapkan langkah augmentasi data seperti resizing, rescaling, flip horizontal, rotasi acak, zoom acak, dan kontras acak pada data pelatihan menggunakan `Sequential` dari TensorFlow.

Jadi, Tujuan keseluruhan kode ini adalah untuk mempersiapkan data dan melakukan augmentasi data untuk proses pelatihan model klasifikasi batik.
"""

# Separate in train and test data
train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)

train_generator = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,
    validation_split=0.2
)

test_generator = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,
)

# Define the function to apply LBP transformation to an image
def apply_lbp(image):
    # Convert the image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    # Apply LBP transformation
    lbp = cv2.LBP(gray, P=8, R=1)
    return lbp

# Data Augmentation Step including LBP transformation
augment = tf.keras.Sequential([
  layers.experimental.preprocessing.Resizing(224,224),
  layers.experimental.preprocessing.Rescaling(1./255),
  layers.experimental.preprocessing.RandomFlip("horizontal"),
  layers.experimental.preprocessing.RandomRotation(0.1),
  layers.experimental.preprocessing.RandomZoom(0.1),
  layers.experimental.preprocessing.RandomContrast(0.1),
  layers.Lambda(lambda x: apply_lbp(x))  # Apply LBP transformation here
])

# Import Data Science Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split

# Tensorflow Libraries
from tensorflow import keras
from tensorflow.keras import layers, models
from keras_preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import Model
from tensorflow.keras.layers.experimental import preprocessing

# System libraries
from pathlib import Path
import os.path
import random

# Visualization Libraries
import matplotlib.cm as cm
import cv2
import seaborn as sns

# Import necessary libraries for LBP
from skimage.feature import local_binary_pattern

sns.set_style('darkgrid')

BATCH_SIZE = 32
TARGET_SIZE = (224, 224)

# Walk through each directory
dataset = "/content/batik/train"
walk_through_dir(dataset);

image_dir = Path(dataset)

# Get filepaths and labels
filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.png'))

labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

# Concatenate filepaths and labels
image_df = pd.concat([filepaths, labels], axis=1)

# Define a function to apply LBP transformation to an image
def apply_lbp(image):
    # Convert the image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    # Apply LBP transformation
    lbp = local_binary_pattern(gray, 8, 1, method='uniform')
    return lbp

# Ensure that dataset is not empty
if not image_df.empty:
    # Display 16 random pictures from the dataset with LBP transformation
    random_index = np.random.randint(0, len(image_df), 16)
    fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),
                            subplot_kw={'xticks': [], 'yticks': []})

    for i, ax in enumerate(axes.flat):
        p = image_df.Filepath[random_index[i]]
        orig = cv2.imread(p)
        orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)
        if i == 1:
            lbp_img = orig.copy()
        else:
            lbp_img = apply_lbp(orig)  # Apply LBP transformation
        ax.imshow(lbp_img, cmap='viridis')  # Show the image with LBP transformation
        ax.set_title(image_df.Label[random_index[i]])
    plt.tight_layout()
    plt.show()
else:
    print("Dataset is empty. Please make sure your dataset is not empty.")

# Split the data into three categories.
train_images = train_generator.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=TARGET_SIZE,
    color_mode='rgb',
    class_mode='categorical',
    batch_size=BATCH_SIZE,
    shuffle=True,
    seed=42,
    subset='training'
)

val_images = train_generator.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=TARGET_SIZE,
    color_mode='rgb',
    class_mode='categorical',
    batch_size=BATCH_SIZE,
    shuffle=True,
    seed=42,
    subset='validation'
)

test_images = test_generator.flow_from_dataframe(
    dataframe=test_df,
    x_col='Filepath',
    y_col='Label',
    target_size=TARGET_SIZE,
    color_mode='rgb',
    class_mode='categorical',
    batch_size=BATCH_SIZE,
    shuffle=False
)

# Data Augmentation Step
augment = tf.keras.Sequential([
  layers.experimental.preprocessing.Resizing(224,224),
  layers.experimental.preprocessing.Rescaling(1./255),
  layers.experimental.preprocessing.RandomFlip("horizontal"),
  layers.experimental.preprocessing.RandomRotation(0.1),
  layers.experimental.preprocessing.RandomZoom(0.1),
  layers.experimental.preprocessing.RandomContrast(0.1),
])

"""# **Pelatihan Model**
Kode ini melakukan beberapa hal terkait dengan pembuatan dan pelatihan model klasifikasi batik diantaranya:

1. Memuat model pre-trained EfficientNetB0 dari TensorFlow, yang telah dilatih pada dataset ImageNet.
2. Menonaktifkan pelatihan pada layer-layer yang ada dalam model pre-trained.
3. Membuat callback untuk menyimpan bobot model terbaik selama pelatihan menggunakan ModelCheckpoint.
4. Menyiapkan callback EarlyStopping untuk menghentikan pelatihan jika val_loss tidak membaik dalam 5 epoch berturut-turut.
5. Mengurangi laju pembelajaran (learning rate) menggunakan ReduceLROnPlateau jika val_loss tidak membaik dalam 3 epoch berturut-turut.
6. Membuat layer untuk augmentasi data yang akan diterapkan pada input gambar.
7. Membangun arsitektur model dengan menambahkan layer-layer tambahan di atas model pre-trained, termasuk layer Dense dengan fungsi aktivasi relu dan Dropout.
8. Mengkompilasi model dengan pengoptimal Adam, fungsi loss categorical_crossentropy, dan metrik akurasi.
9. Melatih model menggunakan metode fit, dengan data pelatihan dan validasi, serta callback yang telah ditentukan sebelumnya. Proses pelatihan ini juga mencatat riwayat pelatihan dalam bentuk file log TensorBoard.
"""

# Load the pretained model
pretrained_model = tf.keras.applications.efficientnet.EfficientNetB0(
    input_shape=(224, 224, 3),
    include_top=False,
    weights='imagenet',
    pooling='max'
)

pretrained_model.trainable = False

# Create checkpoint callback
checkpoint_path = "batik_classification_model_checkpoint"
checkpoint_callback = ModelCheckpoint(checkpoint_path,
                                      save_weights_only=True,
                                      monitor="val_accuracy",
                                      save_best_only=True)

# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs
early_stopping = EarlyStopping(monitor = "val_loss", # watch the val loss metric
                               patience = 5,
                               restore_best_weights = True) # if val loss decreases for 3 epochs in a row, stop training

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)

inputs = pretrained_model.input
x = augment(inputs)

x = Dense(128, activation='relu')(pretrained_model.output)
x = Dropout(0.45)(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.45)(x)


outputs = Dense(15, activation='softmax')(x)

model = Model(inputs=inputs, outputs=outputs)

model.compile(
    optimizer=Adam(0.0001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    train_images,
    steps_per_epoch=len(train_images),
    validation_data=val_images,
    validation_steps=len(val_images),
    epochs=150,
    callbacks=[
        early_stopping,
        create_tensorboard_callback("training_logs",
                                    "batik_classification"),
        checkpoint_callback,
        reduce_lr
    ]
)

"""# **Evaluasi Model**

Precision (P):
Presisi adalah fraksi dari positif benar (TP, prediksi yang benar) dari jumlah hasil yang relevan, yaitu jumlah TP dan positif palsu (FP). Untuk masalah klasifikasi multi-kelas, P dihitung rata-rata di antara semua kelas. Berikut adalah formula untuk presisi.

\[P = \frac{TP}{TP+FP}\]

Recall (R):
Recall adalah fraksi dari TP dari total TP dan negatif palsu (FN). Untuk masalah klasifikasi multi-kelas, R dihitung rata-rata di antara semua kelas. Berikut adalah formula untuk recall.

\[R = \frac{TP}{TP+FN}\]

F1 score (F1):
Skor F1 adalah rata-rata harmonik dari presisi dan recall. Untuk masalah klasifikasi multi-kelas, F1 dihitung rata-rata di antara semua kelas. Berikut adalah formula untuk skor F1.

\[F1 = 2 \times \frac{TP \times FP}{TP + FP}\]



Kode dibawah ini digunakan untuk mengevaluasi performa model klasifikasi batik pada data uji dan memvisualisasikan metrik-metrik kinerja model (akurasi dan loss) selama proses pelatihan.

1. Menggunakan model untuk mengevaluasi performa pada data uji menggunakan metode `evaluate`.
2. Menampilkan nilai loss dan akurasi pada data uji.
3. Membuat plot untuk melihat perubahan akurasi selama pelatihan (`Training accuracy` dan `Validation accuracy`) dari hasil riwayat pelatihan.
4. Membuat plot untuk melihat perubahan loss selama pelatihan (`Training loss` dan `Validation loss`) dari hasil riwayat pelatihan.

Tujuannya adalah untuk mengevaluasi performa model pada data uji dan memantau kinerja model selama pelatihan melalui visualisasi grafik akurasi dan loss.
"""

results = model.evaluate(test_images, verbose=0)

print("    Test Loss: {:.5f}".format(results[0]))
print("Test Accuracy: {:.2f}%".format(results[1] * 100))

accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(accuracy))
plt.plot(epochs, accuracy, 'b', label='Training accuracy')
plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')

plt.title('Training and validation accuracy')
plt.legend()
plt.figure()
plt.plot(epochs, loss, 'b', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')

plt.title('Training and validation loss')
plt.legend()
plt.show()

"""# **Membuat Prediksi Pada gambar tes data**

Kode dibawah ini melakukan prediksi label untuk gambar-gambar pada data uji menggunakan model yang telah dilatih, dan kemudian menampilkan 15 gambar acak dari dataset uji bersama dengan label sebenarnya dan label yang diprediksi. Warna teks judul digunakan untuk menunjukkan apakah prediksi benar (hijau) atau salah (merah).
"""

# Predict the label of the test_images
pred = model.predict(test_images)
pred = np.argmax(pred,axis=1)

# Map the label
labels = (train_images.class_indices)
labels = dict((v,k) for k,v in labels.items())
pred = [labels[k] for k in pred]

# Display the result
print(f'The first 5 predictions: {pred[:5]}')

# Display 25 random pictures from the dataset with their labels
random_index = np.random.randint(0, len(test_df) - 1, 15)
fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15),
                        subplot_kw={'xticks': [], 'yticks': []})

for i, ax in enumerate(axes.flat):
    ax.imshow(plt.imread(test_df.Filepath.iloc[random_index[i]]))
    if test_df.Label.iloc[random_index[i]] == pred[random_index[i]]:
        color = "green"
    else:
        color = "red"
    ax.set_title(f"True: {test_df.Label.iloc[random_index[i]]}\nPredicted: {pred[random_index[i]]}", color=color)
plt.show()
plt.tight_layout()

"""# **Plot & Confusion Matrix**
Tujuan dari kode dibawah ini adalah untuk melakukan evaluasi performa model klasifikasi batik berdasarkan hasil prediksi pada data uji. Langkah-langkah yang dilakukan meliputi:

1. Mencetak laporan klasifikasi yang mendetail, termasuk metrik-metrik seperti presisi, recall, F1-score, dan lainnya, untuk setiap kelas yang ada dalam data uji.
2. Menghasilkan laporan klasifikasi dalam bentuk DataFrame untuk memudahkan analisis lebih lanjut.
"""

y_test = list(test_df.Label)
print(classification_report(y_test, pred))

report = classification_report(y_test, pred, output_dict=True)
df = pd.DataFrame(report).transpose()
df

"""# **Visualisasi Grad-Cam**
Fungsi-fungsi dalam kode dibawah ini bertujuan untuk melakukan visualisasi Grad-CAM (Gradient-weighted Class Activation Mapping) untuk memahami bagian mana dari gambar yang dianggap penting oleh model klasifikasi dalam proses pengambilan keputusan.

- `get_img_array`: Mengonversi gambar menjadi array yang dapat digunakan oleh model, dan menambahkan dimensi batch.
- `make_gradcam_heatmap`: Menghasilkan heatmap Grad-CAM untuk memahami kontribusi relatif dari setiap bagian gambar terhadap prediksi model.
- `save_and_display_gradcam`: Menggabungkan heatmap dengan gambar asli untuk menciptakan visualisasi Grad-CAM, yang menyoroti bagian-bagian penting dari gambar.

Setelah fungsi-fungsi ini didefinisikan, mereka digunakan untuk memvisualisasikan Grad-CAM dari gambar-gambar dalam dataset uji. Setiap gambar diberi peringkat sesuai dengan prediksi model, dan bagian-bagian yang ditekankan oleh Grad-CAM ditampilkan untuk memahami dasar dari prediksi tersebut.
"""

def get_img_array(img_path, size):
    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)
    array = tf.keras.preprocessing.image.img_to_array(img)
    # We add a dimension to transform our array into a "batch"
    # of size "size"
    array = np.expand_dims(array, axis=0)
    return array

def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    # First, we create a model that maps the input image to the activations
    # of the last conv layer as well as the output predictions
    grad_model = tf.keras.models.Model(
        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]
    )

    # Then, we compute the gradient of the top predicted class for our input image
    # with respect to the activations of the last conv layer
    with tf.GradientTape() as tape:
        last_conv_layer_output, preds = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]
    # This is the gradient of the output neuron (top predicted or chosen)
    # with regard to the output feature map of the last conv layer
    grads = tape.gradient(class_channel, last_conv_layer_output)

    # This is a vector where each entry is the mean intensity of the gradient
    # over a specific feature map channel
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # We multiply each channel in the feature map array
    # by "how important this channel is" with regard to the top predicted class
    # then sum all the channels to obtain the heatmap class activation
    last_conv_layer_output = last_conv_layer_output[0]
    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)

    # For visualization purpose, we will also normalize the heatmap between 0 & 1
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()
def save_and_display_gradcam(img_path, heatmap, cam_path="cam.jpg", alpha=0.4):
    # Load the original image
    img = tf.keras.preprocessing.image.load_img(img_path)
    img = tf.keras.preprocessing.image.img_to_array(img)

    # Rescale heatmap to a range 0-255
    heatmap = np.uint8(255 * heatmap)

    # Use jet colormap to colorize heatmap
    jet = cm.get_cmap("jet")

    # Use RGB values of the colormap
    jet_colors = jet(np.arange(256))[:, :3]
    jet_heatmap = jet_colors[heatmap]

    # Create an image with RGB colorized heatmap
    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)
    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))
    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)

    # Superimpose the heatmap on original image
    superimposed_img = jet_heatmap * alpha + img
    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)
    # Save the superimposed image
    superimposed_img.save(cam_path)

    # Display Grad CAM
#     display(Image(cam_path))

    return cam_path


preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input
decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions

last_conv_layer_name = "top_conv"
img_size = (224,224, 3)

# Remove last layer's softmax
model.layers[-1].activation = None

# Display the part of the pictures used by the neural network to classify the pictures
fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 10),
                        subplot_kw={'xticks': [], 'yticks': []})

for i, ax in enumerate(axes.flat):
    img_path = test_df.Filepath.iloc[random_index[i]]
    img_array = preprocess_input(get_img_array(img_path, size=img_size))
    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)
    cam_path = save_and_display_gradcam(img_path, heatmap)
    ax.imshow(plt.imread(cam_path))
    ax.set_title(f"True: {test_df.Label.iloc[random_index[i]]}\nPredicted: {pred[random_index[i]]}")
plt.tight_layout()
plt.show()